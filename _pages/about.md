---
layout: archive
permalink: /
title: "Mingrui YU / 于铭瑞 / Harry YU"
excerpt: "About me"
author_profile: true
redirect_from:
  - /about/
  - /about.html
---

<head>
  <link rel="stylesheet" href="_pages/styles.css">
</head>

I am Mingrui YU, a robotics researcher. I'm now pursuing the Ph.D. degree in the [Intelligent Manipulation Lab](https://thu-irml.com), Department of Automation, Tsinghua University, supervised by [Prof. Xiang Li](https://sites.google.com/view/homepageoflixiang/home).
From 10/2023 to 03/2024, I was a visiting student at the [MSC Lab](https://msc.berkeley.edu/) in UC Berkeley, supervised by [Prof. Masayoshi Tomizuka](https://me.berkeley.edu/people/masayoshi-tomizuka/).

**Research Interest**:
My research focuses on advancing reliable and accurate **robotic dexterous manipulation** by addressing challenges arising from the diversity of manipulated objects, the high dimensionality of robot motions, and the complexity of physical contacts.
I prefer to approach problems from a robotics standpoint, prioritizing interpretable methods and guaranteed performance in physical systems.
I believe the most promising path to human-level dexterity lies in the elegant integration of rigorous analytical motion computation, self-learning through exploration, and learning from large-scale human demonstrations.
My prior research includes dexterous in-hand manipulation, grasping, and deformable object manipulation.

I am leading an NSFC Youth Student Research Project (for PhD students) / 首批国家自然科学基金青年学生基础研究项目（博士生项目）entitled "Visual-tactile dexterous manipulation of deformable linear objects with a dual-arm robot".

**Future Opportunities**: I am open to potential academic and industry job opportunities following my graduation in June 2026. Please feel free to contact me.

Email: [mingruiyu98@gmail.com](mailto:mingruiyu98@gmail.com) (recommended); [ymr20@mails.tsinghua.edu.cn](mailto:ymr20@mails.tsinghua.edu.cn) (国内使用).

---

# Education

**Department of Automation, Tsinghua University (Beijing, China)** &emsp; _08/2020 - 06/2026 (expected)_  
Ph.D. Student in Control Science and Engineering  
GPA: 3.95/4.0, Ranking: 3/84

**Department of Automation, Xi'an Jiaotong University (Xi'an, China)** &emsp; _08/2016 - 07/2020_  
B.Eng. in Automation (Honors Engineering Program, 钱学森班)  
GPA: 4.09/4.3, Ranking: 1/35

---

# Research Experience

**General Vision Lab, Beijing Institute of General Artificial Intelligence (BIGAI) (Beijing, China)** &emsp; _04/2025 - present_  
Advisor: Dr. Tengyu Liu, Dr. Siyuan Huang  
Topic: Learning dexterous manipulation from humans

**Robotics X, Tencent (Shenzhen, China)** &emsp; _06/2024 - 09/2024_  
Advisor: Dr. Yu Zheng  
Topic: Dexterous grasping and manipulation

**Mechanical Systems Control Lab, University of California, Berkeley** &emsp; _10/2023 - 03/2024_  
Advisor: Prof. Masayoshi Tomizuka  
Topic: Dexterous manipulation of (deformable) objects

**Institute of Automation, Chinese Academy of Sciences (Beijing, China)** &emsp; _07/2018 - 06/2019_  
Advisor: Prof. Yisheng Lv  
Topic: Reinforment learning for intelligent transportation system

---

# Selected Publications

Please refer to the [Publications page](https://mingrui-yu.github.io/publications) or <a href="https://scholar.google.com/citations?user=021Lx3IAAAAJ&hl=en">my Google Scholar profile</a> for all publications.

<div class="paper-container">
  <!-- Left side: GIF -->
  <div class="gif-container">
    <img src="files/publications/jiang2025model.gif" alt="GIF Description" class="paper-gif">
  </div>
  <!-- Right side: Paper Information -->
  <div class="info-container">
    <p class="paper-title">Robust Model-Based In-Hand Manipulation with Integrated Real-Time Motion-Contact Planning and Tracking</p>
    <p class="authors"> Y. Jiang, <b>M. Yu</b>, X. Zhu, M. Tomizuka, and X. Li </p>
    <p class="journal"> Submitted to The International Journal of Robotics Research (<b>IJRR</b>), 2025 </p>
    <p class="url"> [<a href="https://arxiv.org/abs/2505.04978">Paper</a>]  [<a href="https://director-of-g.github.io/in_hand_manipulation_2/">Website</a>] </p>
  </div>
</div>

<div class="paper-container">
  <!-- Left side: GIF -->
  <div class="gif-container">
    <img src="files/publications/lv2025kinematic.gif" alt="GIF Description" class="paper-gif">
  </div>
  <!-- Right side: Paper Information -->
  <div class="info-container">
    <p class="paper-title">Kinematics-Aware Diffusion Policy with Consistent 3D Observation and Action Space for Whole-Arm Robotic Manipulation</p>
    <p class="authors"> K. Lv*, <b>M. Yu</b>*, Y. Jia, C. Zhang, and X. Li </p>
    <p class="journal"> Submitted to IEEE Robotics and Automation Letters (<b>RA-L</b>), 2025  </p>
    <p class="url"> [<a href="https://kinematics-aware-diffusion-policy.github.io">Website</a>] </p>
  </div>
</div>

<div class="paper-container">
  <!-- Left side: GIF -->
  <div class="gif-container">
    <img src="files/publications/xin2025analyzing.gif" alt="GIF Description" class="paper-gif">
  </div>
  <!-- Right side: Paper Information -->
  <div class="info-container">
    <p class="paper-title">Analyzing Key Objectives in Human-to-Robot Retargeting for Dexterous Manipulation</p>
    <p class="authors"> C. Xin*, <b>M. Yu</b>*, Y. Jiang, Z. Zhang, and X. Li </p>
    <p class="journal"> Submitted to IEEE Robotics and Automation Practice (<b>RA-P</b>), 2025  </p>
    <p class="info"> Presented at ICRA 2025 Workshop"Handy Moves: Dexterity in Multi-Fingered Hands" </p>
    <p class="url"> [<a href="https://openreview.net/forum?id=ojCJehWjy7">Paper</a>] [<a href="https://mingrui-yu.github.io/retargeting/">Website</a>] </p>
  </div>
</div>

<div class="paper-container">
  <!-- Left side: GIF -->
  <div class="gif-container">
    <img src="files/publications/jiang2025robust.gif" alt="GIF Description" class="paper-gif">
  </div>
  <!-- Right side: Paper Information -->
  <div class="info-container">
    <p class="paper-title">Robust In-Hand Reorientation with Hierarchical RL-Based Motion Primitives and Model-Based Regrasping</p>
    <p class="authors"> Y. Jiang, <b>M. Yu</b>, C. Chen, Y. Jia, and X. Li </p>
    <p class="journal"> Submitted to IEEE Robotics and Automation Practice (<b>RA-P</b>), 2025  </p>
    <p class="info"> Part of the <b>1st Place Solution</b> in the In-Hand Manipulation Track & the <b>Most Elegant Solution</b> of ICRA 2024 Robotic Grasping and Manipulation Competition (RGMC)</p>
    <p class="url">  [<a href="https://rgmc-xl-team.github.io/inhand_reorientation/">Website</a>] </p>
  </div>
</div>

<div class="paper-container">
  <!-- Left side: GIF -->
  <div class="gif-container">
    <img src="files/publications/yu2024robotic.gif" alt="GIF Description" class="paper-gif">
  </div>
  <!-- Right side: Paper Information -->
  <div class="info-container">
    <p class="paper-title">Robotic In-Hand Manipulation for Large-Range and Precise Object Movement: The RGMC Champion Solution</p>
    <p class="authors"> <b>M. Yu</b>, Y. Jiang, C. Chen, Y. Jia, and X. Li </p>
    <p class="journal"> IEEE Robotics and Automation Letters (<b>RA-L</b>), 2025  </p>
    <p class="info"> Part of the <b>1st Place Solution</b> in the In-Hand Manipulation Track & the <b>Most Elegant Solution</b> of ICRA 2024 Robotic Grasping and Manipulation Competition (RGMC)</p>
    <p class="url"> [<a href="https://arxiv.org/abs/2502.07472">Paper</a>] [<a href="https://rgmc-xl-team.github.io/ingrasp_manipulation/">Website</a>] </p>
  </div>
</div>

<div class="paper-container">
  <!-- Left side: GIF -->
  <div class="gif-container">
    <img src="files/publications/yu2024inhand.gif" alt="GIF Description" class="paper-gif">
  </div>
  <!-- Right side: Paper Information -->
  <div class="info-container">
    <p class="paper-title">In-Hand Following of Deformable Linear Objects Using Dexterous Fingers With Tactile Sensing</p>
    <p class="authors"> <b>M. Yu</b>, B. Liang, X. Zhang, X. Zhu, L. Sun, C. Wang, X. Li, M. Tomizuka </p>
    <p class="journal"> IEEE/RSJ International Conference on Intelligent Robots and Systems (<b>IROS</b>), 2024 (<b>Oral</b>) </p>
    <p class="url"> [<a href="https://arxiv.org/abs/2403.12676">Paper</a>] [<a href="https://mingrui-yu.github.io/DLO_following/">Website</a>] </p>
  </div>
</div>

<div class="paper-container">
  <!-- Left side: GIF -->
  <div class="gif-container">
    <img src="files/publications/jiang2024contact.gif" alt="GIF Description" class="paper-gif">
  </div>
  <!-- Right side: Paper Information -->
  <div class="info-container">
    <p class="paper-title">Contact-Implicit Model Predictive Control for Dexterous In-hand Manipulation: A Long-Horizon and Robust Approach</p>
    <p class="authors"> Y. Jiang, <b>M. Yu</b>, X. Zhu, M. Tomizuka, X. Li </p>
    <p class="journal"> IEEE/RSJ International Conference on Intelligent Robots and Systems (<b>IROS</b>), 2024  </p>
    <p class="url"> [<a href="https://arxiv.org/abs/2402.18897">Paper</a>] [<a href="https://director-of-g.github.io/in_hand_manipulation/">Website</a>] </p>
  </div>
</div>

<div class="paper-container">
  <!-- Left side: GIF -->
  <div class="gif-container">
    <img src="files/publications/yu2024generalizable_small.gif" alt="GIF Description" class="paper-gif">
  </div>
  <!-- Right side: Paper Information -->
  <div class="info-container">
    <p class="paper-title">Generalizable whole-body global manipulation of deformable linear objects by dual-arm robot in 3-D constrained environments</p>
    <p class="authors"> <b>M. Yu</b>, K. Lv, C. Wang, Y. Jiang, M. Tomizuka, and X. Li </p>
    <p class="journal"> The International Journal of Robotics Research (<b>IJRR</b>), 2024  </p>
    <p class="url"> [<a href="https://arxiv.org/abs/2310.09899">Paper</a>] [<a href="https://mingrui-yu.github.io/DLO_planning_2/">Website</a>] </p>
  </div>
</div>

<div class="paper-container">
  <!-- Left side: GIF -->
  <div class="gif-container">
    <img src="files/publications/yu2023global.gif" alt="GIF Description" class="paper-gif">
  </div>
  <!-- Right side: Paper Information -->
  <div class="info-container">
    <p class="paper-title">Global Model Learning for Large Deformation Control of Elastic Deformable Linear Objects: An Efficient and Adaptive Approach</p>
    <p class="authors"> <b>M. Yu</b>, K. Lv, H. Zhong, S. Song, and X. Li </p>
    <p class="journal"> IEEE Transactions on Robotics (<b>T-RO</b>), 2023  </p>
    <p class="url"> [<a href="https://arxiv.org/abs/2205.04004">Paper</a>] [<a href="https://mingrui-yu.github.io/shape_control_DLO_2/">Website</a>] </p>
  </div>
</div>

<div class="paper-container">
  <!-- Left side: GIF -->
  <div class="gif-container">
    <img src="files/publications/yu2023coarse.gif" alt="GIF Description" class="paper-gif">
  </div>
  <!-- Right side: Paper Information -->
  <div class="info-container">
    <p class="paper-title">A Coarse-to-Fine Framework for Dual-Arm Manipulation of Deformable Linear Objects with Whole-Body Obstacle Avoidance</p>
    <p class="authors"> <b>M. Yu</b>, K. Lv, C. Wang, M. Tomizuka, and X. Li </p>
    <p class="journal"> IEEE International Conference on Robotics and Automation (<b>ICRA</b>), 2023  </p>
    <p class="info"> <b>Best Paper Award</b> at the ICRA 2023 Workshop on Representing and Manipulating Deformable Objects </p>
    <p class="url"> [<a href="https://arxiv.org/abs/2209.11145">Paper</a>] [<a href="https://mingrui-yu.github.io/DLO_planning">Website</a>] </p>
  </div>
</div>

<div class="paper-container">
  <!-- Left side: GIF -->
  <div class="gif-container">
    <img src="files/publications/lv2023learning_small.gif" alt="GIF Description" class="paper-gif">
  </div>
  <!-- Right side: Paper Information -->
  <div class="info-container">
    <p class="paper-title">Learning to Estimate 3-D states of Deformable Linear Objects from Single-Frame Occluded Point Clouds</p>
    <p class="authors"> K. Lv, <b>M. Yu</b>, Y. Pu, X. Jiang, G. Huang, and X. Li </p>
    <p class="journal"> IEEE International Conference on Robotics and Automation (<b>ICRA</b>), 2023  </p>
    <p class="url"> [<a href="https://arxiv.org/abs/2210.01433">Paper</a>] [<a href="https://mingrui-yu.github.io/videos/ICRA23_DLO_perception_video.mp4">Video</a>] </p>
  </div>
</div>

<div class="paper-container">
  <!-- Left side: GIF -->
  <div class="gif-container">
    <img src="files/publications/yu2022shape.gif" alt="GIF Description" class="paper-gif">
  </div>
  <!-- Right side: Paper Information -->
  <div class="info-container">
    <p class="paper-title">Shape Control of Deformable Linear Objects with Offline and Online Learning of Local Linear Deformation Models</p>
    <p class="authors"> <b>M. Yu</b>, H. Zhong, and X. Li </p>
    <p class="journal"> IEEE International Conference on Robotics and Automation (<b>ICRA</b>), 2022  </p>
    <p class="url"> [<a href="https://arxiv.org/abs/2109.11091">Paper</a>] [<a href="https://mingrui-yu.github.io/shape_control_DLO/">Website</a>] </p>
  </div>
</div>

<div class="paper-container">
  <!-- Left side: GIF -->
  <div class="gif-container">
    <img src="files/publications/DLO_review_16_9.jpg" alt="GIF Description" class="paper-gif">
  </div>
  <!-- Right side: Paper Information -->
  <div class="info-container">
    <p class="paper-title">面向线状柔性物体的机器人操作研究进展与展望</p>
    <p class="authors"> <b>于铭瑞</b>, 李翔 </p>
    <p class="journal"> <a href="https://robot.sia.cn/">机器人</a>, 2024  </p>
    <p class="url"> [<a href="https://robot.sia.cn/article/doi/10.13973/j.cnki.robot.240139">Paper</a>] </p>
  </div>
</div>

---

# Competitions

- 1st Place in ICRA 2024 Robotic Grasping and Manipulation Competition - In-Hand Manipulation Track [[Certificate](https://mingrui-yu.github.io/files/24_ICRA_RGMC_Inhand.jpg)] & The Most Elegant Solution Award Among All Tracks [[Certificate](https://mingrui-yu.github.io/files/24_ICRA_RGMC_Elegant.jpg)] &emsp; _2024_
- 2nd Place in ICRA 2023 Virtual Manipulation Challenge [[Certificate](https://mingrui-yu.github.io/files/23_icra_virtual_manipulation_challenge_certificate.pdf)] &emsp; _2023_
- 2nd Place in ICRA 2022 RoboMaster University Sim2Real Challenge [[Certificate](https://mingrui-yu.github.io/files/22_icra_sim2real_certificate.pdf)] &emsp; _2022_
- COMAP Mathematical Contest in Modeling, Finalist Winners (Top 0.5%) [[Certificate](https://mingrui-yu.github.io/files/18_mcm_certificate.pdf)] &emsp; _2018_

---

# Awards & Honors

- China Association for Science and Technology, Youth Talent Support Program for PhD students (中国科协青年人才托举工程博士生专项项目) &emsp; _2024_
- Tsinghua Jiang Nan-Xiang Scholarship (清华大学蒋南翔奖学金) [[Certificate](../files/24_jiangnanxiang.pdf)] &emsp; _2024_
- China National Scholarship for Graduate Students (研究生国家奖学金) [[Certificate](../files/24_national_scholarship.pdf)] &emsp; _2024_
- Best Paper Award at [ICRA 2023 Workshop on Representing and Manipulating Deformable Objects](https://deformable-workshop.github.io/icra2023/) &emsp; _2023_
- T.J. Tarn Best Paper Award in Robotics Finalist at 2023 IEEE ROBIO [[Certificate](https://mingrui-yu.github.io/files/23_ROBIO_award.pdf)] &emsp; _2023_
- Tsinghua Comprehensive Excellence Scholarship (清华大学综合优秀奖学金) &emsp; _2022/2023_
- Outstanding Graduate at XJTU (西安交大优秀毕业生) &emsp; _2020_
- First-Class Scholarship at XJTU (西安交大一等奖学金) &emsp; _2019_
- China National Scholarship for Undergraduate Students (本科生国家奖学金) [[Certificate](../files/18_national_scholarship.pdf)] &emsp; _2018_
- Outstanding Student at XJTU (西安交大优秀学生) &emsp; _2017/2018/2019_

---

# Projects

[Project Page](https://mingrui-yu.github.io/projects)

---

# Academic Service

- Outstanding reviewer of IEEE Robotics and Automation Letters [[Certificate](https://mingrui-yu.github.io/files/24_RAL_outstanding_reviewer.jpg)]
- Outstanding volunteer of 2023 IEEE International Conference on Real-Time Computing and Robotics (RCAR) [[Certificate](https://mingrui-yu.github.io/files/23_rcar_volunteer.pdf)]
- Reviewer for IJRR, T-RO, T-ASE, T-Mech, RA-L, ...
- Reviewer for ICRA, IROS, ...
